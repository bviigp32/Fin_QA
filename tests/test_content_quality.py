import pytest
import requests

BASE_URL = "http://127.0.0.1:8000"

# ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ (Blacklist)
# ì‹¤ì œ í˜„ì—…ì—ì„œëŠ” DBë‚˜ ë³„ë„ íŒŒì¼ë¡œ ê´€ë¦¬í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
BANNED_WORDS = ["sh*t", "f**k", "damn", "trash"]

def test_no_profanity_in_content():
    """
    [CNT-001] ì½˜í…ì¸  ë¹„ì†ì–´(Profanity) í•„í„°ë§ í…ŒìŠ¤íŠ¸
    - ë‰´ìŠ¤ ë³¸ë¬¸(content)ì— ê¸ˆì¹™ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì•ˆ ëœë‹¤.
    - ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  ê²€ì‚¬í•œë‹¤.
    """
    print("\n[QA] ì½˜í…ì¸  ìœ í•´ì„± ê²€ì‚¬ ì‹œì‘ (Profanity Check)...")
    
    # ë°ì´í„° ë§ì´ ìš”ì²­ (20ê°œ) -> ë²„ê·¸ ê±¸ë¦´ í™•ë¥  ë†’ì´ê¸°
    response = requests.get(f"{BASE_URL}/news?limit=20")
    assert response.status_code == 200
    
    news_list = response.json()["items"]
    caught_bad_words = []

    for index, news in enumerate(news_list):
        content = news.get("content", "")
        
        # ë³¸ë¬¸ì´ ë¹„ì–´ìˆìœ¼ë©´ íŒ¨ìŠ¤ (ì´ê±´ Day 3ì˜ Null ì²´í¬ì—ì„œ ì¡ì„ ë¬¸ì œ)
        if not content:
            continue

        # ğŸ” ê¸ˆì¹™ì–´ ìŠ¤ìº” ë¡œì§
        for bad_word in BANNED_WORDS:
            # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ë¹„êµ (lower())
            if bad_word in content.lower():
                print(f"\n[Catch!] ë¹„ì†ì–´ ë°œê²¬ (Index: {index})")
                print(f"   - Ticker: {news['ticker']}")
                print(f"   - ê¸ˆì¹™ì–´: '{bad_word}'")
                print(f"   - ì›ë¬¸: \"{content}\"")
                
                caught_bad_words.append({
                    "id": news['id'],
                    "word": bad_word,
                    "content": content
                })
                break # í•œ ë‰´ìŠ¤ì— ìš•ì´ ì—¬ëŸ¬ ê°œì—¬ë„ í•œ ë²ˆë§Œ ê±¸ë¦¬ë©´ ë¨

    # ê²°ê³¼ íŒì •
    if len(caught_bad_words) > 0:
        pytest.fail(f"ì´ {len(caught_bad_words)}ê±´ì˜ ìœ í•´ ì½˜í…ì¸ ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤! ë°°í¬ ë¶ˆê°€!")
    else:
        print("í´ë¦°í•œ ë‰´ìŠ¤ì…ë‹ˆë‹¤. (Clean Content)")